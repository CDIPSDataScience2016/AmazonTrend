{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, we will create a html report for the amazon reviews of a single product (currently Samsung Chromebook).\n",
    "\n",
    "TO DO:\n",
    "-Classify reviews using pickled model trained on Electronics data.\n",
    "-Classify sentences using this classifier rather than text blobs.\n",
    "-Generalize, so that can input product name, retrieve asin from metadata and then produce report."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First read in and clean Product Reviews (this should be changed that it is for any arbitrary product at some point)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "popular_product = pd.read_csv(\"Samsung_chromebook_review.csv\", sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import datetime\n",
    "popular_product['unixReviewTime'] = pd.to_datetime(popular_product['unixReviewTime'],unit='s')\n",
    "popular_product[\"overall\"] = popular_product[\"overall\"].astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sort product reviews into positive or negative depending on star rating (this needs to be replaced with whichever pickled classifier we decide on)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "popular_product[\"overall\"] = popular_product[\"overall\"].astype(int)\n",
    "\n",
    "#popular_product = popular_product[popular_product[\"overall\"] != 3]\n",
    "#popular_product[\"sentiment\"] = popular_product[\"overall\"] >= 4\n",
    "\n",
    "pos_reviews = popular_product[popular_product[\"overall\"] >= 4]\n",
    "neg_reviews = popular_product[popular_product[\"overall\"] <= 2]\n",
    "\n",
    "pos_reviews.index = range(0,len(pos_reviews))\n",
    "neg_reviews.index = range(0,len(neg_reviews))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#bin number of reviews by month and year. First all reviews\n",
    "time_dist=popular_product.groupby([popular_product.unixReviewTime.dt.year,popular_product.unixReviewTime.dt.month]).overall.count()\n",
    "\n",
    "df_time = time_dist.to_frame()\n",
    "df_time[\"date\"] = pd.to_datetime( time_dist.index, format='(%Y, %m)')\n",
    "\n",
    "#Now positive and negative reviews\n",
    "pos_time_dist=pos_reviews.groupby([pos_reviews.unixReviewTime.dt.year,pos_reviews.unixReviewTime.dt.month]).overall.count()\n",
    "neg_time_dist=neg_reviews.groupby([neg_reviews.unixReviewTime.dt.year,neg_reviews.unixReviewTime.dt.month]).overall.count()\n",
    "\n",
    "pos_time = pos_time_dist.to_frame()\n",
    "pos_time[\"date\"] = pd.to_datetime( pos_time.index, format='(%Y, %m)')\n",
    "\n",
    "neg_time = neg_time_dist.to_frame()\n",
    "neg_time[\"date\"] = pd.to_datetime( neg_time.index, format='(%Y, %m)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot total reviews vs time and save URL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import plotly.plotly as py\n",
    "import plotly.graph_objs as go\n",
    "\n",
    "#Only include months with more than one review - Amazon seems to accidently include some reviews for other products pre 2012...\n",
    "\n",
    "trace1 = go.Scatter(\n",
    "    x=df_time[\"date\"][df_time[\"overall\"] > 1],\n",
    "    y=df_time[\"overall\"][df_time[\"overall\"] > 1],\n",
    ")\n",
    "data = [trace1]\n",
    "\n",
    "layout = go.Layout(\n",
    "    title='Reviews vs time',\n",
    "    xaxis=dict(\n",
    "        title='Date',\n",
    "    ),\n",
    "    yaxis=dict(\n",
    "        title='Number of reviews',\n",
    "    ),\n",
    "    showlegend=False\n",
    ")\n",
    "\n",
    "fig = go.Figure(data=data, layout=layout)\n",
    "all_reviews_plot_url = py.plot(fig, filename='reviews_vs_time')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot positive and negative reviews vs time and save URL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Only include months with more than one review - Amazon seems to accidently include some reviews for other products pre 2012...\n",
    "\n",
    "trace1 = go.Scatter(\n",
    "    x=pos_time[\"date\"][pos_time[\"overall\"] > 1],\n",
    "    y=pos_time[\"overall\"][pos_time[\"overall\"] > 1],\n",
    "    name=\"positive reviews\"\n",
    ")\n",
    "trace2 = go.Scatter(\n",
    "    x=neg_time[\"date\"][neg_time[\"overall\"] > 1],\n",
    "    y=neg_time[\"overall\"][neg_time[\"overall\"] > 1],\n",
    "    name=\"negative reviews\"\n",
    ")\n",
    "data = [trace1, trace2]\n",
    "\n",
    "layout = go.Layout(\n",
    "    title='Reviews vs time',\n",
    "    xaxis=dict(\n",
    "        title='Date',\n",
    "    ),\n",
    "    yaxis=dict(\n",
    "        title='Number of reviews',\n",
    "    ),\n",
    "    showlegend=True\n",
    ")\n",
    "\n",
    "fig = go.Figure(data=data, layout=layout)\n",
    "sent_reviews_plot_url = py.plot(fig, filename='sent_reviews_vs_time')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now clean and POS tag text and get noun phrases for positive and negative sentences. Mostly use textblobs library for this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import nltk.data\n",
    "from textblob import TextBlob\n",
    "import re\n",
    "\n",
    "tokenizer = nltk.data.load('tokenizers/punkt/english.pickle')\n",
    "\n",
    "\n",
    "def review_to_sentences( review, tokenizer ):\n",
    "    sentences = tokenizer.tokenize(review.strip())\n",
    "    blobs = []\n",
    "    review_sentences = []\n",
    "    for sentence in sentences:\n",
    "        if len(sentence) > 0:\n",
    "            review_sentences.append( sentence)\n",
    "            blobs.append(TextBlob(sentence))\n",
    "    return review_sentences\n",
    "\n",
    "def review_to_blobs( review, tokenizer ):\n",
    "    blobs = []\n",
    "    review_sentences = []\n",
    "    sentences = tokenizer.tokenize(review.strip())\n",
    "    for sentence in sentences:\n",
    "        if len(sentence) > 0:\n",
    "            sentence = re.sub(\"[^a-zA-Z]\", \" \", sentence)\n",
    "            review_sentences.append( sentence)\n",
    "            blobs.append(TextBlob(sentence))\n",
    "    return blobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsing sentences from training set\n",
      "Cleaning and tokenizing review 1000 of 4580\n",
      "Cleaning and tokenizing review 2000 of 4580\n",
      "Cleaning and tokenizing review 3000 of 4580\n",
      "Cleaning and tokenizing review 4000 of 4580\n"
     ]
    }
   ],
   "source": [
    "blobs = []\n",
    "review_sentences = []\n",
    "\n",
    "print(\"Parsing sentences from training set\")\n",
    "icount = 1\n",
    "for review in popular_product[\"reviewText\"]:\n",
    "    icount += 1\n",
    "    if icount%1000 == 0:\n",
    "        print(\"Cleaning and tokenizing review\", icount, \"of\", len(popular_product))\n",
    "    review_sentences += review_to_sentences(review, tokenizer)\n",
    "    blobs += review_to_blobs(review, tokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Positive nouns phrases selected from sentences with sentiment above 0.3. Negative noun phrases selected from sentences with sentiment below -0.3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "positive_sentences = []\n",
    "negative_sentences = []\n",
    "\n",
    "positive_noun_phrases = []\n",
    "negative_noun_phrases = []\n",
    "for blob in blobs:\n",
    "    if blob.polarity > 0.3:\n",
    "        positive_sentences.append(blob)\n",
    "        positive_noun_phrases.append(blob.noun_phrases)\n",
    "    elif blob.polarity < -0.3:\n",
    "        negative_sentences.append(blob)\n",
    "        negative_noun_phrases.append(blob.noun_phrases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "negative_phrases = []\n",
    "for noun_phrases in negative_noun_phrases:\n",
    "    for noun_phrase in noun_phrases:\n",
    "        negative_phrases.append(noun_phrase)\n",
    "        \n",
    "positive_phrases = []\n",
    "for noun_phrases in positive_noun_phrases:\n",
    "    for noun_phrase in noun_phrases:\n",
    "        positive_phrases.append(noun_phrase)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find most frequent positive and negative noun phrases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfTransformer, CountVectorizer\n",
    "import numpy as np\n",
    "import re\n",
    "import nltk\n",
    "import string\n",
    "\n",
    "from nltk.tokenize.punkt import PunktSentenceTokenizer\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.feature_extraction.text import TfidfTransformer, CountVectorizer\n",
    "\n",
    "def get_word_freq(words):\n",
    "    vectorizer = CountVectorizer(analyzer = \"word\", tokenizer = None, preprocessor = None, stop_words = None, max_features = 1000, ngram_range=(2,3)) \n",
    "    \n",
    "    word_features = vectorizer.fit_transform(words)\n",
    "    word_features = word_features.toarray()\n",
    "    \n",
    "    vocab = vectorizer.get_feature_names()\n",
    "    \n",
    "    dist = np.sum(word_features, axis=0)\n",
    "\n",
    "    word_freq = {'count': dist, 'vocab': vocab}\n",
    "    word_freq = pd.DataFrame(word_freq)\n",
    "    word_freq = word_freq.sort_values(by=\"count\",ascending=False)\n",
    "    return word_freq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "freq_pos = get_word_freq(positive_phrases)\n",
    "freq_neg = get_word_freq(negative_phrases)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Put top 5 positive and negative noun phrases in table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "top_five_neg = freq_neg.head(5)\n",
    "\n",
    "neg_table = top_five_neg.to_html().replace('<table border=\"1\" class=\"dataframe\">','<table class=\"table table-striped\">')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "top_five_pos = freq_pos.head()\n",
    "\n",
    "pos_table = top_five_pos.to_html().replace('<table border=\"1\" class=\"dataframe\">','<table class=\"table table-striped\">')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "html_string = '''\n",
    "<html>\n",
    "    <head>\n",
    "        <link rel=\"stylesheet\" href=\"https://maxcdn.bootstrapcdn.com/bootstrap/3.3.1/css/bootstrap.min.css\">\n",
    "        <style>body{ margin:0 100; background:whitesmoke; }</style>\n",
    "    </head>\n",
    "    <body>\n",
    "        <h1>Amazon Product Reviews for Samsung Chromebook</h1>\n",
    "\n",
    "        <!-- *** Section 1 *** --->\n",
    "        <h2>Figure 1: Total number of reviews over time</h2>\n",
    "        <iframe width=\"1000\" height=\"550\" frameborder=\"0\" seamless=\"seamless\" scrolling=\"no\" \\\n",
    "src=\"''' + all_reviews_plot_url + '''.embed?width=800&height=550\"></iframe>\n",
    "        <p>There are many reviews immeadiately after product release, then decreases over time.</p>\n",
    "        \n",
    "        <!-- *** Section 2 *** --->\n",
    "        <h2>Figure 2: Positive and negative reviews over time</h2>\n",
    "        <iframe width=\"1000\" height=\"550\" frameborder=\"0\" seamless=\"seamless\" scrolling=\"no\" \\\n",
    "src=\"''' + sent_reviews_plot_url + '''.embed?width=1000&height=550\"></iframe>\n",
    "        <p>Negative reviews remain roughly constant over time, whereas positive rise initially and then fall over time.\\\n",
    "        Slight peaks in positive reviews maybe related to sales times, eg. January 2014?</p>\n",
    "        <h3>Top 5 noun phrases for positive reviews</h3>\n",
    "        ''' + pos_table + '''\n",
    "        <h3>Top 5 noun phrases for negative reviews</h3>\n",
    "        ''' + neg_table + '''\n",
    "    </body>\n",
    "</html>'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "f = open('Samsung_chromebook_product_review_report.html','w')\n",
    "f.write(html_string)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
